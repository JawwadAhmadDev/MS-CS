{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "998d1109",
   "metadata": {},
   "source": [
    "\n",
    "# Diabetes Prediction — Using a Local CSV (Beginner friendly)\n",
    "\n",
    "This notebook uses a local CSV file `pima_diabetes_dataset_offline.csv` (placed in the same folder).\n",
    "It performs a full ML workflow with explanations:\n",
    "- Load local CSV\n",
    "- Inspect data and handle missing values\n",
    "- Preprocess (replace invalid zeros, impute using median, scale features)\n",
    "- Train 5 classifiers (Logistic Regression, Decision Tree, Random Forest, KNN, SVC)\n",
    "- Evaluate models (accuracy, ROC-AUC, classification report, confusion matrix)\n",
    "- Plot model comparison and give short assignment notes\n",
    "\n",
    "Run the notebook cells top-to-bottom. The notebook is written for beginners with comments and brief explanations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b35dcf",
   "metadata": {},
   "source": [
    "## 1) Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3cd71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cd5ea5",
   "metadata": {},
   "source": [
    "## 2) Load the local CSV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e730c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load local CSV (ensure the file is in the same folder as this notebook)\n",
    "csv_path = 'pima_diabetes_dataset_offline.csv'  # change path if needed\n",
    "df = pd.read_csv(csv_path)\n",
    "print('Loaded shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf86f7cb",
   "metadata": {},
   "source": [
    "## 3) Basic inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fadb9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print('\\nSummary statistics:\\n', df.describe().T)\n",
    "print('\\nTarget value counts:\\n', df['Outcome'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64836114",
   "metadata": {},
   "source": [
    "## 4) Robust target handling (ensure y is numeric 0/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962340a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust target mapping (handles string labels if present)\n",
    "y = df['Outcome']\n",
    "import numpy as np\n",
    "if not np.issubdtype(pd.Series(y).dtype, np.number):\n",
    "    print('Non-numeric target detected. Examples:', pd.Series(y).unique()[:20])\n",
    "    mapping = {\n",
    "        'tested_negative': 0, 'tested_positive': 1,\n",
    "        'negative': 0, 'positive': 1,\n",
    "        'No': 0, 'Yes': 1,\n",
    "        'no': 0, 'yes': 1,\n",
    "        'NEGATIVE': 0, 'POSITIVE': 1,\n",
    "        '0': 0, '1': 1\n",
    "    }\n",
    "    y_mapped = pd.Series(y).map(mapping)\n",
    "    if y_mapped.isna().any():\n",
    "        coerced = pd.to_numeric(pd.Series(y), errors='coerce')\n",
    "        if coerced.isna().any():\n",
    "            missing = pd.Series(y)[y_mapped.isna()].unique()\n",
    "            raise ValueError(f'Cannot automatically map these target labels: {missing}. Add them to mapping.')\n",
    "        else:\n",
    "            y = coerced.astype(int)\n",
    "    else:\n",
    "        y = y_mapped.astype(int).values\n",
    "else:\n",
    "    y = pd.Series(y).astype(int).values\n",
    "\n",
    "print('Final target unique values:', np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07821b9",
   "metadata": {},
   "source": [
    "## 5) Preprocessing: replace invalid zeros, impute, and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = df.drop(columns=['Outcome']).copy()\n",
    "\n",
    "# Columns where 0 is medically invalid and likely represents missing values\n",
    "cols_with_zero_invalid = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "# Replace zeros with NaN in those columns\n",
    "X[cols_with_zero_invalid] = X[cols_with_zero_invalid].replace(0, np.nan)\n",
    "print('Missing counts after replacing zeros:')\n",
    "print(X[cols_with_zero_invalid].isna().sum())\n",
    "\n",
    "# Impute missing values with median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns=X_imputed.columns)\n",
    "\n",
    "print('\\nAfter imputation and scaling — feature summary:')\n",
    "print(X_scaled.describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6729fbee",
   "metadata": {},
   "source": [
    "## 6) Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.30, random_state=42, stratify=y)\n",
    "print('Train shape:', X_train.shape)\n",
    "print('Test shape:', X_test.shape)\n",
    "print('Train class distribution:\\n', pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64099c21",
   "metadata": {},
   "source": [
    "## 7) Train 5 models and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d9aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'SVC': SVC(probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    try:\n",
    "        roc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "    except Exception:\n",
    "        roc = None\n",
    "    results.append({'model': name, 'accuracy': acc, 'roc_auc': roc})\n",
    "    print(f'--- {name} ---')\n",
    "    print('Accuracy:', round(acc, 4))\n",
    "    print('Classification report:\\n', classification_report(y_test, y_pred))\n",
    "    print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "    print('\\n')\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values('accuracy', ascending=False).reset_index(drop=True)\n",
    "print('Summary results:')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeed6a86",
   "metadata": {},
   "source": [
    "## 8) Plot model accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a529f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(results_df['model'], results_df['accuracy'])\n",
    "plt.title('Model accuracy comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "for i, v in enumerate(results_df['accuracy']):\n",
    "    plt.text(i, v+0.01, f'{v:.3f}', ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2930355",
   "metadata": {},
   "source": [
    "## 9) Assignment notes and suggestions\n",
    "- Explain why zeros were replaced with NaN for certain columns.\n",
    "- Explain median imputation.\n",
    "- Explain why scaling is needed for KNN and SVM.\n",
    "- Suggest next steps: cross-validation, hyperparameter tuning, feature selection, ensemble methods."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
